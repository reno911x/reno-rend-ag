{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utdycYwDl473"
      },
      "source": [
        "Rendering notebook for Ariana Grande AI\n",
        "Trained by MusicStar AI Team [ https://musicstar.ai ] for use by beta testers.* Do not distribute.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup should take >=2 minutes, rendering time may vary depending on GPU.\n",
        "â¬‡ï¸ Run Setup to get started."
      ],
      "metadata": {
        "id": "1TOh8NCZkMgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVGW0xAXKCzg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #Setup ðŸ› ï¸\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "!rm -rf /content/sample_data\n",
        "!python -m pip install -q --upgrade pip\n",
        "!python -m pip install -q --upgrade wheel\n",
        "#!apt-get install -q unzip\n",
        "!pip install -q -U --no-cache-dir gdown --pre\n",
        "!pip install -q --pre torchtext==0.6.0 --no-deps\n",
        "\n",
        "import gdown\n",
        "d = 'https://drive.google.com/uc?id='\n",
        "\n",
        "\n",
        "!git clone https://github.com/reno911x/reno-rendering &> /dev/null\n",
        "%cd \n",
        "\n",
        "%cd \"/content/reno-rendering/\"\n",
        "!pip install -q -r requirements_short.txt\n",
        "\n",
        "%cd\n",
        "\n",
        "%mkdir -p /content/reno-rendering/checkpoints/\n",
        "gdown.download(d+r'1X8e-Y62TjdbOVURayXqA_wB9-twoiGWi')\n",
        "!unzip \"checkpoints.zip\" -d /content/reno-rendering/\n",
        "!rm checkpoints.zip\n",
        "\n",
        "gdown.download(d+r'1YBBGb0cGdkTb047nwbppzm3-6bg10KP2', \"ariana.zip\")\n",
        "!unzip \"ariana.zip\" -d /content/ariana/\n",
        "!rm ariana.zip\n",
        "\n",
        "%cd \"/content/reno-rendering\"\n",
        "os.environ[\"PYTHONPATH\"]='.'\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0\n",
        "from utils.hparams import hparams\n",
        "from preprocessing.data_gen_utils import get_pitch_parselmouth,get_pitch_crepe\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import utils\n",
        "import librosa\n",
        "import torchcrepe\n",
        "from infer import *\n",
        "import logging\n",
        "from infer_tools.infer_tool import *\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "project_name = \"ariana_rendering\"\n",
        "\n",
        "svc_model = Svc(project_name,\"/content/ariana/ariana/config.yaml\", True, \"/content/ariana/ariana/model_ckpt_steps_100000.ckpt\")\n",
        "\n",
        "print(\"\\n* âœ… Setup Completed *\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOcWLNgmTp5g",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown #Reference Audio Setup ðŸ’¿\n",
        "#@markdown ---\n",
        "#@markdown Upload a \".wav\" file to the runtime and copy and paste path here.\n",
        "wav_fn='/content/omg.wav' #@param {type: \"string\"}\n",
        "demoaudio, sr = librosa.load(wav_fn)\n",
        "\n",
        "#@markdown Shifts by a semitone, can be positive or negative [ 0 nuetral, 5 for higher pitch voices, and -5 for lower pitch voices. ] * Test with 0 first *\n",
        "key = 0 #@param {type: \"integer\"}\n",
        "\n",
        "wav_gen = 'output.wav' \n",
        "\n",
        "pndm_speedup = 0 \n",
        "use_crepe = True\n",
        "use_pe = True\n",
        "thre = 0.05\n",
        "use_gt_mel = False\n",
        "add_noise_step = 500\n",
        "\n",
        "f0_tst, f0_pred, audio = run_clip(svc_model,file_path=wav_fn, key=key, acc=pndm_speedup, use_crepe=use_crepe, use_pe=use_pe, thre=thre,\n",
        "                                        use_gt_mel=use_gt_mel, add_noise_step=add_noise_step,project_name=project_name,out_path=wav_gen)\n",
        "\n",
        "print('* âœ… Rendering Completed *')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GpV_EtHUm5L",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown #Play A.I Output ðŸ¤–ðŸŽ¶\n",
        "#@markdown Right click and \"save as\" to save the file.\n",
        "!pip3 install pydub\n",
        "\n",
        "import pydub\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "from IPython.display import HTML\n",
        "\n",
        "import IPython.display as ipd\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "from pydub import AudioSegment\n",
        "sound = AudioSegment.from_wav(\"/content/reno-rendering/output.wav\")\n",
        "sound.export(\"/content/reno-rendering/output.mp3\", format=\"mp3\")\n",
        "\n",
        "\n",
        "ipd.Audio('/content/reno-rendering/output.mp3')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}